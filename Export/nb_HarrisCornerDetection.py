
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/HarrisCornerDetection.ipynb
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib
from matplotlib.patches import ConnectionPatch
from dataclasses import dataclass
from matplotlib.patches import Circle

from Export.nb_Convolutions1D import oneDimConvolution, gaussianConv, derivative
from Export.nb_ConvertToHSV import convertToGrey, showEachChannel
from Export.nb_PixelManipulation import getChannels, iterateImage, timeSomething
from Export.nb_HistogramEqualisation import compareTwoImages

def computeGradientPolyImage(img: np.array, kernel_size: int):
    _, height, width, channels, _ = getChannels(img)
    if channels != 1 : print('Incorrect input size'); return
    hori_deriv = oneDimConvolution(img.copy(), derivative(kernel_size), True)
    vert_deriv = oneDimConvolution(img.copy(), derivative(kernel_size), False)
    output_img = np.dstack((hori_deriv, vert_deriv, np.zeros((height, width), dtype = np.float32)))
    i, j, k = 0, 0, 0
    for px in np.nditer(output_img, order = 'C', op_flags = ['readwrite']):
        if k == 0:
            current_x = px
        elif k == 1:
            current_y = px
        else:
            px[...] = current_x * current_y
            current_x[...] **= 2
            current_y[...] **= 2
        i, j, k = iterateImage(i, j, k, 3, width)
    return output_img

def determinantOverTrace(Ix2: float, Iy2: float, IyIx: float):
    trace = Ix2 + Iy2
    det = Ix2*Iy2 - IyIx**2
    angle = Ix2 - Iy2
    mag = np.sqrt(trace)
    if angle == 0:
        np.pi/2 * np.sign(IyIx)
    else:
        angle = np.arctan(2*IyIx/angle)/2
    if trace == 0: return 0, 0, 0
    return (mag, angle, det/trace)

def updateMinMaxChannels(output_vector: tuple, max_channels: dict, min_channels: dict):
    for channel in max_channels.keys():
        if output_vector[channel] > max_channels[channel]:
            max_channels[channel] = output_vector[channel]
        if output_vector[channel] < min_channels[channel]:
            min_channels[channel] = output_vector[channel]

def divideByMaxChannels(img: np.array, max_channels: dict, min_channels: dict):
    for channel, max_channel in max_channels.items():
        min_channel = min_channels[channel]
        img[:, :, channel] -= min_channel
        max_channel -= min_channel
        if max_channel > 0: img[:, :, channel] /= max_channel

def computeCornerMeasure(img: np.array, cornerMeasure):
    _, _, width, channels, _ = getChannels(img)
    if channels != 3 : print('Incorrect numer of input channels'); return
    i, j, k = 0, 0, 0
    max_channels = {0:0,1:0,2:0}
    min_channels = {0:0,1:0,2:0}
    for px in np.nditer(img, order = 'C', op_flags = ['readwrite']):
        if k == 0:
            current_x = px
        elif k == 1:
            current_y = px
        else:
            output_vector = cornerMeasure(current_x, current_y, px)
            current_x[...] = output_vector[0]
            current_y[...] = output_vector[1]
            px[...] = output_vector[2]
            updateMinMaxChannels(output_vector, max_channels, min_channels)
        i, j, k = iterateImage(i, j, k, 3, width)
    divideByMaxChannels(img, max_channels, min_channels)
    return img

def harrisCornerImage(img : np.array, derivative_size: int, blur_size: int, energyFunction):
    grad_frog = computeGradientPolyImage(img, derivative_size)
    blur_y, blur_x = gaussianConv(blur_size, blur_size)
    grad_frog = oneDimConvolution(grad_frog, blur_y, False)
    grad_frog = oneDimConvolution(grad_frog, blur_x, True)
    return computeCornerMeasure(grad_frog, energyFunction)

@dataclass
class HarrisMatch:
    coordinateA: np.array = np.array([0,0], dtype = np.float32)
    coordinateB: np.array = np.array([0,0], dtype = np.float32)
    affinity:float = 0.

    def drawPointToPoint(self, target_axis: plt.axis, init_axis: plt.axis, px1: np.array, px2: np.array, **kwargs):
        target_axis.plot([px1[0]],[px1[1]], 'rx', markersize=10)
        con = ConnectionPatch(xyA=px1, xyB=px2, coordsA="data", coordsB="data",
                        axesA=target_axis, axesB=init_axis, **kwargs)
        target_axis.add_artist(con)

    def drawOnAxes(self, ax1: plt.axis, ax2: plt.axis, **kwargs):
        self.drawPointToPoint(ax1, ax2, self.coordinateA, self.coordinateB, **kwargs)
        self.drawPointToPoint(ax2, ax1, self.coordinateB, self.coordinateA, **kwargs)

def drawArrowsOnImages(image1: np.array, image2: np.array, matches: list, cmap_image: str, cmap_match: str, **kwargs):
    cmap = matplotlib.cm.ScalarMappable(
      norm = matplotlib.colors.Normalize(0, 255),
      cmap = cmap_match
    )
    cmap.set_array([])
    norm = matplotlib.colors.Normalize(vmin=0, vmax=255)
    ax1, ax2, fig = compareTwoImages(image1, image2, cmap = cmap_image)
    for match in matches:
        kwargs['color'] = cmap.to_rgba(match.affinity)[:3]
        match.drawOnAxes(ax1, ax2, **kwargs)
    fig.subplots_adjust(bottom=0.1)
    plt.colorbar(cmap, orientation='horizontal', cax = fig.add_axes([0.2, 0.05, 0.6, 0.03]));
    plt.gca().set_xlabel('Match Affinity', fontsize=16);

@dataclass
class HarrisPoint:
    feature_vector: np.array = np.array([], dtype = np.float32)
    coordinate: np.array = np.array([0,0], dtype = np.float32)
    magnitude: float = 0.
    angle:float = 0.
    corner_measure:float = 0.
    assignment: bool = False

    def __len__(self):
        return len(self.feature_vector)

    def __getitem__(self, idx):
        return self.feature_vector[idx]

    def distanceTo(self, i: int, j: int):
        distance = self.coordinate - (i, j)
        return np.dot(distance, distance)

    def normaliseHist(self):
        hist_norm = np.linalg.norm(self.feature_vector)
        if hist_norm > 0: self.feature_vector /= hist_norm

    def updateHistogram(self, n_hist_buckets, k: int, px: float):
        hist_index = int(n_hist_buckets * px)
        hist_index += k * n_hist_buckets
        self.feature_vector[hist_index] += 1

    def __str__(self):
        if len(self) < 11:
            out_str = 'Hp : ' + str(self.coordinate) + '|' + str([np.round(feat, 3) for feat in self.feature_vector[:10]])
            out_str = out_str[:-1] + ', ... ]'
            return out_str
        else:
            return 'Hp : ' + str(self.coordinate) + '|' + str([np.round(feat, 3) for feat in self.feature_vector[:10]])

class HarrisPointArray:
    def __init__(self, feature_len: int, distance_thresh: float):
        self.points = []
        self.template_array = np.ndarray(feature_len, dtype = np.float32)
        self.template_array.fill(0.)
        self.feature_len = feature_len
        self.distance_euclid = distance_thresh
        self.distance_thresh = distance_thresh ** 2

    def addPoint(self, i: int, j: int, mag: float, angle: float, corner: float):
        new_point = HarrisPoint(
            self.template_array.copy(),
            np.array([i, j], dtype = np.float32),
            mag, angle, corner
        )
        self.points.append(new_point)

    def checkAllDistances(self, i: int, j: int):
        for point in self:
            if point.distanceTo(i, j) < self.distance_thresh:
                return point
        return

    def getHistogramBuckets(self, channels: int):
        if self.feature_len % channels != 0:
            print('Warning: feature vector is not a mutiple of feature channels')
        return self.feature_len // channels

    def normaliseAllHistograms(self):
        for point in self: point.normaliseHist()

    def plotPoints(self, img: np.array, circ_color = 'w', **kwargs):
        plt.imshow(img, **kwargs)
        ax = plt.gca()
        for point in self:
            plt.scatter(*reversed(point.coordinate))
            circ = Circle(
                tuple(reversed(point.coordinate)),
                radius = self.distance_euclid,
                fill = False,
                color = circ_color
            )
            ax.add_patch(circ)

    def deassignAllPoints(self):
        for point in self: point.assignment = False

    def __len__(self):
        return len(self.points)

    def __str__(self):
        n_iterations = 0
        output_str = 'Hp Arr -' + str(len(self)) + ' points -{\n'
        for point in self:
            output_str += str(point)
            output_str += '\n'
            n_iterations += 1
            if n_iterations > 10:
                output_str += '... \n';break
        output_str += '}'
        return output_str

    def __iter__(self):
        for point in self.points:
            yield point

def thresholdHarrisWithinDistance(harris_img: np.array, corner_thresh: float, distance_thresh: float, feature_len: int):
    _, _, width, channels, _ = getChannels(harris_img)
    if channels != 3 : print('Incorrect numer of input channels'); return
    harris_points = HarrisPointArray(feature_len, distance_thresh)

    i, j, k = 0, 0, 0
    for px in np.nditer(harris_img, order = 'C', op_flags = ['readwrite']):
        if k == 0:
            curr_x = px
        elif k == 1:
            curr_y = px
        else:
            if px > corner_thresh:
                if not harris_points.checkAllDistances(i, j):
                    harris_points.addPoint(i, j, curr_y, curr_x, px)
        i, j, k = iterateImage(i, j, k, 3, width)
    return harris_points

def normaliseImage(img: np.array):
    img, _, _, channels, _ = getChannels(img)
    img = np.float32(img)
    for k in range(channels):
        min_img = np.min(np.array(img[:,:,k]))
        max_img = np.max(np.array(img[:,:,k])) - min_img + 0.001
        img[:,:,k] += min_img
        if max_img != 0:
            img[:,:,k] /= max_img
    return img

def createFeatureImage(*args):
    base_height = None
    base_width = None
    total_channels = 0
    channel_arr = []

    for img in args:
        _, height, width, channels, _ = getChannels(img)
        channel_arr += [channels]
        if not base_height: base_height = height
        elif base_height != height:
            print('Error! Not all input images have the same height.'); return
        if not base_width: base_width = width
        elif base_height != height:
            print('Error! Not all input images have the same height.'); return
        total_channels += channels

    feat_img = np.ndarray((base_height, base_width, total_channels), dtype = np.float32)
    current_channel = 0
    img_ind = 0
    for img in args:
        img = normaliseImage(img)
        next_channel = current_channel + channel_arr[img_ind]
        feat_img[:, :, current_channel:next_channel] = img
        current_channel = next_channel
        img_ind += 1
    return feat_img

def getFeatureVectorsFromCornerPoints(harris_points: HarrisPointArray, feature_images: np.ndarray):
    _, _, width, channels, _ = getChannels(feature_images)
    n_hist_buckets = harris_points.getHistogramBuckets(channels)

    i, j, k = 0, 0, 0
    for px in np.nditer(feature_images, order = 'C', op_flags = ['readwrite']):
        if k == 0: matched_point = harris_points.checkAllDistances(i, j)
        if matched_point: matched_point.updateHistogram(n_hist_buckets, k, px)
        i, j, k = iterateImage(i, j, k, channels, width)
    harris_points.normaliseAllHistograms()
    return harris_points

def dotProductSimiliarity(point1, point2):
    return 255 * np.dot(point1.feature_vector, point2.feature_vector)

def findBestHarrisMatches(harris_points: HarrisPointArray, harris_points_other: HarrisPointArray,
                          min_match_ratio: float, kernelFunction, min_matches: int):
    output_matches = []
    harris_points.deassignAllPoints()
    harris_points_other.deassignAllPoints()
    for point in harris_points:
        best_match = 0; best_point = None
        second_best_match = 0
        n_matches = 0
        for other_point in harris_points_other:
            if not point.assignment and not other_point.assignment:
                similiarity = kernelFunction(point, other_point)
                n_matches += 1
                if similiarity > best_match:
                    second_best_match = best_match
                    best_match = similiarity
                    best_point = other_point
                elif similiarity > second_best_match:
                    second_best_match = similiarity
        if best_match > 0 and second_best_match/best_match < min_match_ratio and n_matches > min_matches:
            best_point.assignment = True
            output_matches.append(
                HarrisMatch(tuple(reversed(point.coordinate)),
                            tuple(reversed(best_point.coordinate)),
                            best_match)
            )
    return output_matches

def radianToDegrees(x):
    return x * 180 / np.pi

def getImageCenter(img):
    _, height, width, _, _ = getChannels(img)
    c_h = (height - 1)/2
    c_w = (width - 1)/2
    return np.array([c_h, c_w], dtype = np.float32)

def fitRotationalTransformation(harris_matches: list, center_point: np.array, distance_thresh: float):
    valid_estimates = []
    for match in harris_matches:
        coordA = center_point - match.coordinateA
        coordB = center_point - match.coordinateB
        normA = np.linalg.norm(coordA)
        normB = np.linalg.norm(coordB)
        norm_diff = np.abs(normA - normB)
        if norm_diff < distance_thresh:
            dot_prod = np.dot(coordA, coordB) / (normA * normB)
            angle = np.arccos(dot_prod)
            valid_estimates.append(radianToDegrees(angle))
    return np.median(valid_estimates)

def getHarrisPoints(img: np.array, feat_img: np.array,
                    derivative_size: int, blur_size: int, cornerFunction,
                    corner_threshold: float, harris_distance: float, feature_his_len: int):

    harris_img = harrisCornerImage(img, derivative_size, blur_size, cornerFunction)
    harris_points = thresholdHarrisWithinDistance(harris_img, corner_threshold, harris_distance, feature_his_len)
    harris_points = getFeatureVectorsFromCornerPoints(harris_points, feat_img)
    return harris_points

def estimateRotation(img: np.array, rot_img: np.array, feat_img: np.array, rot_feat_img: np.array,
                     derivative_size: int, blur_size: int, cornerFunction, corner_threshold: float,
                     harris_distance: float, feature_his_len: int,
                     min_match_ratio: float, kernelFunction, min_matches: int, norm_change_thresh: float):

    image_center = getImageCenter(img)
    image_center_rot = getImageCenter(rot_img)
    if np.linalg.norm(image_center - image_center_rot) > 1e-7:
        print('Error: Image centers not the same!'); return

    harris_points = getHarrisPoints(img, feat_img, derivative_size, blur_size, cornerFunction, corner_threshold, harris_distance, feature_his_len)
    rot_harris_points = getHarrisPoints(rot_img, rot_feat_img, derivative_size, blur_size, cornerFunction, corner_threshold, harris_distance, feature_his_len)
    harris_matches = findBestHarrisMatches(harris_points, rot_harris_points, min_match_ratio, kernelFunction, min_matches)
    rotation = fitRotationalTransformation(harris_matches, image_center, norm_change_thresh)
    return rotation